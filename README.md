# Oficina SOAT

_Tech challenge_ da pÃ³s tech em arquitetura de software - FIAP Fase 2

# Alunos

- Felipe
    - RM: `365154`
    - discord: `felipeoli7eira`
    - LinkedIn: [@felipeoli7eira](https://www.linkedin.com/in/felipeoli7eira)
- Nicolas
    - RM: `365746`
    - discord: `nic_hcm`
    - LinkedIn: [@Nicolas Martins](https://www.linkedin.com/in/nicolas-henrique/)
- William
    - RM: `365973`
    - discord: `wllsistemas`
    - LinkedIn: [@William Francisco Leite](https://www.linkedin.com/in/william-francisco-leite-9b3ba9269/?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)

# Material
- [VÃ­deo de apresentaÃ§Ã£o](https://www.youtube.com/watch?v=POC_FaWt39E)
- [Documento de entrega - PDF](https://drive.google.com/file/d/1Xl_8YgZHRIELfM3yCWjbswp4tD7Gxoin/view?usp=drive_link)

# Sobre o projeto
Este projeto foi desenvolvido com [Laravel](https://laravel.com), [nginx](https://nginx.org) e [postgresql](https://www.postgresql.org) e por volta dessas 3 tecnologias, estÃ¡ o [docker](https://www.docker.com)/[docker compose](https://docs.docker.com/compose) e toda uma arquitetura com kubernetes que entraremos em mais detalhes em seÃ§Ãµes posteriores.


O Laravel foi escolhido por ser um dos principais (se nÃ£o o principal) framework PHP atualmente, e por suas facilidades para criar APIs **RESTful** de verdade, com o mÃ­nimo de esforÃ§o. Com ele conseguimos alcanÃ§ar a [excelÃªncia do modelo de maturidade REST](https://mundoapi.com.br/destaques/alcancando-a-excelencia-do-rest-com-um-modelo-de-maturidade-eficiente/). AlÃ©m disso, sÃ£o mais de 10 anos no campo de batalha, comprovando sua eficiÃªncia e seguranÃ§a, alÃ©m de uma grande comunidade e um ecossistema que nÃ£o para de crescer.


O **Nginx** foi escolhido como servidor web por sua [arquitetura assÃ­ncrona orientada a eventos](https://nginx.org/en/docs/http/ngx_http_core_module.html), que permite lidar com milhares de conexÃµes simultÃ¢neas consumindo poucos recursos do sistema.
Diferente do Apache em seus modos mais tradicionais (como o MPM prefork, que cria um processo por conexÃ£o), o Nginx adota um modelo de worker processes, onde cada processo Ã© capaz de gerenciar milhares de conexÃµes de forma nÃ£o bloqueante, por meio de I/O assÃ­ncrono. Isso o torna altamente eficiente em ambientes com alta concorrÃªncia. Embora o Apache tambÃ©m tenha evoluÃ­do e ofereÃ§a um modo event mais moderno, o Nginx ainda Ã© amplamente preferido em contextos de alta performance.
AlÃ©m disso, sua configuraÃ§Ã£o tende a ser mais simples e direta para casos como servir arquivos estÃ¡ticos, atuar como _reverse proxy_ para aplicaÃ§Ãµes PHP-FPM, fazer load balancing ou cache de conteÃºdo.
Essa eficiÃªncia e flexibilidade explicam sua ampla adoÃ§Ã£o por [grandes empresas como Netflix, Airbnb e Dropbox](https://www.nginx.com/case-studies/), que o utilizam para escalar aplicaÃ§Ãµes em ambientes de alta demanda.


O **PostgreSQL** Ã© uma escolha de longo prazo segura, [preparada para o futuro](https://www.enterprisedb.com/blog/postgres-developers-favorite-database-2024?lang=en). O que o destaca Ã© a [maneira como ele lida com tarefas bÃ¡sicas e complexas](https://www.nucamp.co/blog/coding-bootcamp-backend-with-python-2025-postgresql-vs-mysql-in-2025-choosing-the-best-database-for-your-backend) - desde armazenamento simples de dados atÃ© recursos avanÃ§ados, como tratamento de dados geoespaciais e suporte nativo a JSON. Postgres [virou lÃ­der em 6 anos](https://survey.stackoverflow.co/2024/technology#1-databases), saindo de 33% para 49% de uso vs MySQL que caiu de 59% para ~40%. NÃ³s o escolhemos por sua [escalabilidade, extensibilidade, licenÃ§a e outros](https://www.bytebase.com/blog/postgres-vs-mysql/).

# DocumentaÃ§Ã£o sobre infra

## Desenho da Arquitetura

![clean-arch.png](./docs/img/arquitetura-kubernetes.png)

## ðŸ³ Deploy da AplicaÃ§Ã£o

- Foram escritos 2 arquivos Dockerfile que estÃ£o na pasta **./build/backend**
    1. **nginx**
    2. **php:8.4-fpm-alpine3.22**

> [!NOTE]
> O container PostgreSQL Ã© criado a partir de uma imagem no Docker Hub **postgres:17.5**.

> [!NOTE]
> O banco de dados da aplicaÃ§Ã£o Ã© criado apÃ³s o container do **PHP** ser executado, as rotinas de **migrations** e **seeders** sÃ£o executadas via comando `artisan` do laravel durante a inicializaÃ§Ã£o do container, atravÃ©s do script **/build/backend/startup.sh**.


#### Build Imagem Docker
- **Nginx**: executar comando Ã  partir da raiz do projeto
```bash
  docker build -t wllsistemas/nginx_lab_soat:fase2 -f build/backend/Dockerfile-nginx .
```
- **PHP + CÃ³digo Fonte**: executar comando Ã  partir da raiz do projeto
```bash
  docker build -t wllsistemas/php_lab_soat:fase2 -f build/backend/Dockerfile .
```

## â˜¸ï¸ kubernetes

Todos os manifestos kubernetes estÃ£o dentro da pasta **./k8s**, os manifestos foram nomeados para facilitar a ordem de execuÃ§Ã£o.

#### Arquivos de Manifesto
```bash
  00-metrics-server.yaml **
  01-namespace.yaml
  02-configmap.yaml
  03-secret.yaml
  04-secret-postgres.yaml
  05-pv-postgres.yaml
  06-pvc-postgres.yaml
  07-svc-postgres.yaml
  08-svc-php.yaml
  09-svc-nginx.yaml
  10-pod-postgres.yaml
  11-pod-php.yaml
  12-pod-nginx.yaml
  13-hpa-ngix.yaml
```
### Namespace kubernetes
Para melhor organizaÃ§Ã£o do ambiente, todos os manifestos sÃ£o criados dentro do namespace **lab-soat** atravÃ©s do manifesto **01-namespace.yaml**.

### PrÃ©-requisitos
- docker >= 28.4.0
- kubeadm >= 1.34.1
- kubectl >= 1.32.2

### Como Executar todos os manifestos
Executar o comando abaixo Ã  partir da raiz do projeto

```bash
  kubectl apply -f ./k8s
```

### Listando ServiÃ§os e Portas
Executar o comando abaixo Ã  partir da raiz do projeto, passando o namespace **lab-soat**

```bash
  kubectl get services -n lab-soat
```

#### Portas de Acesso
| Service | Port | Type |
|---|---|---|
|svc-php|9000|ClusterIP|
|postgres|5432|ClusterIP|
|svc-ngix|31000|NodePort|

### URL de acesso Health Check
```bash
  http://localhost:31000/api/ping
```


### Como Deletar todo o Ambiente
Esse comando deleta todos os componentes do namespace **lab-soat**

```bash
  kubectl delete namespace lab-soat
```

> [!NOTE]
> As imagens buildadas estÃ£o no repositÃ³rio [Docker Hub](https://hub.docker.com/repositories/wllsistemas)

> [!WARNING]
> O manifesto **metrics-server.yaml** foi necessÃ¡rio em nosso Ambiente para criaÃ§Ã£o dos recursos de mÃ©tricas utilizados pelo **hpa**, ele insere no args a flag abaixo.

```bash
  - --kubelet-insecure-tls
```

## ðŸŒ Terraform

Todos os scripts **Terraform** estÃ£o dentro da pasta **./infra**.

### PrÃ©-requisitos
- docker >= 28.4.0
- kubeadm >= 1.34.1
- kubectl >= 1.32.2
- terraform >= 1.13.3

### Recursos do Cluster

> [!NOTE]
> Ã‰ necessÃ¡rio criar recursos de mÃ©tricas em nÃ­vel de cluster, esses recursos estÃ£o na subpasta **./infra/cluster_base** e precisam ser criados apenas na primeira execuÃ§Ã£o.

#### Navegar atÃ© o diretÃ³rio dos scripts
```bash
  cd infra/cluster_base
```

#### Inicializar terraform
```bash
  terraform init
```

#### Executar comando de anÃ¡lise do cÃ³digo
```bash
  terraform plan
```

#### Como Executar todos os scripts
```bash
  terraform apply
```

### Recursos da AplicaÃ§Ã£o

> [!NOTE]
> Recursos da aplicaÃ§Ã£o setÃ£o na pasta **./infra** e podem ser destruÃ­dos com o comando `destroy`.

#### Navegar atÃ© o diretÃ³rio dos scripts
```bash
  cd infra
```

#### Inicializar terraform
```bash
  terraform init
```

#### Executar comando de anÃ¡lise do cÃ³digo
```bash
  terraform plan -var="php_image_tag=fase2" -var="nginx_image_tag=fase2"
```

#### Como Executar todos os scripts
Executar o comando abaixo, passando como parÃ¢metro o valor das variÃ¡veis contendo as TAGs das imagens no Docker Hub.

```bash
  terraform apply -auto-approve -var="php_image_tag=fase2" -var="nginx_image_tag=fase2"
```

#### Como Deletar todo o Ambiente
Esse comando deleta todos os componentes

```bash
  terraform destroy -auto-approve -var="php_image_tag=fase2" -var="nginx_image_tag=fase2"
```

## ðŸ“ˆ HPA (HorizontalPodAutoscaler)
Escrevemos um manifesto kubernetes `13-hpa-nginx.yaml` para automatizar o escalonamento horizontal dos pods **lab-soat-nginx** com base em mÃ©tricas de utilizaÃ§Ã£o.

| MÃ©trica | Valor | Und Medida |
|---|---|---|
| UtilizaÃ§Ã£o de CPU | 10 | % |
|MÃ©dia de Consumo MemÃ³ria RAM| 10 | MegaBytes |

O HPA garante que o Deployment **lab-soat-nginx** tenha entre 1 e 10 pods, escalando para cima se a utilizaÃ§Ã£o mÃ©dia da CPU exceder 10% (em relaÃ§Ã£o ao request do pod) ou se o consumo mÃ©dio de memÃ³ria exceder 10Mi. O objetivo Ã© manter a performance da aplicaÃ§Ã£o otimizada, adicionando ou removendo pods conforme a demanda, sem intervenÃ§Ã£o manual

## ðŸš€ Pipeline GitHub Actions

#### 1. AprovaÃ§Ã£o de um PR para merge com a `main`
No branch `main` sÃ£o efetuados merges mediante aprovaÃ§Ã£o dos PRs.

#### 2. ExecuÃ§Ã£o da Pipeline CI
Ao executar o merge, Ã© disparada a pipeline `ci.yaml` que executa:
- Testes UnitÃ¡rios e IntegraÃ§Ã£o
- Build da Imagem no Docker Hub
- Envia e-mail customizado em caso de Sucesso ou Falha

#### 3. ExecuÃ§Ã£o da Pipeline CD
ApÃ³s a execuÃ§Ã£o da pipeline CD , Ã© disparada a pipeline `cd.yaml` que executa:
- Valida a execuÃ§Ã£o da pipeline CI
- Copia os manifestos kubernetes para VPS
- Aplica os manifestos na VPS, atualizando aplicaÃ§Ã£o
- Envia e-mail customizado em caso de Sucesso ou Falha

# Setup local

Antes de fazer o clone do projeto, precisamos ter em mente algumas coisas:

Como especificado no arquivo [docker-compose.yaml](./docker-compose.yml), um container de postgres serÃ¡ criado na porta padrÃ£o (`5432`) com mapeamento `5432:5432` (`host:container`).

O nginx estÃ¡ configurado para fazer o proxy reverso para o container de php (veja o arquivo [nginx.conf](./build/server/nginx.conf) para mais detalhes). Ã‰ pelo container de nginx que a api Ã© acessada, entÃ£o quando tudo estiver pronto, vocÃª poderÃ¡ acessar `http://localhost:8080/api` e como teste rÃ¡pido, acessar o endpoint `http://localhost:8080/api/ping`. O resultado esperado Ã© a seguinte response:

```json
{
  "msg": "pong",
  "err": false
}
```

Ã‰ importante que vocÃª esteja certo de que as portas `5432` e `8080` no seu computador estejam liberadas para que esses serviÃ§os sejam alocados corretamente nelas. Caso contrÃ¡rio, certamente erros irÃ£o ocorrer. Uma alternativa serÃ¡ editar o [docker-compose.yaml](./docker-compose.yml) mudando as portas de host dos serviÃ§os, para portas que estejam liberadas na sua mÃ¡quina.


Clone este repositÃ³rio
```sh
git clone git@github.com:felipeoli7eira/oficina-soat.git
```

Entre na pasta criada
```sh
cd oficina-soat
```

Suba os containers
```sh
docker compose up -d --build
```

O resultado esperado Ã© que 3 containers estejam em pleno funcionamento:
- php (9000/tcp)
- nginx (0.0.0.0:8080->80/tcp)
- postgres (0.0.0.0:5432->5432/tcp)

Agora, como dito anteriormente, vocÃª pode tentar acessar o endpoint `http://localhost:8080/api/ping` e verificar se a api responde com "pong".

# Testes

O projeto conta com testes unitÃ¡rios e de integraÃ§Ã£o desenvolvidos com PHPUnit. Os testes garantem a qualidade e confiabilidade do cÃ³digo, cobrindo desde a lÃ³gica de domÃ­nio atÃ© a persistÃªncia de dados.

## Executando os Testes Localmente

Com os containers em execuÃ§Ã£o, vocÃª pode rodar os testes usando o seguinte comando:

```sh
docker compose exec php php artisan test
```

Para executar os testes com relatÃ³rio de cobertura:

```sh
docker compose exec php php artisan test --coverage
```

Para uma visualizaÃ§Ã£o mais compacta:

```sh
docker compose exec php php artisan test --coverage --compact
```

![testes.png](./docs/img/testes.png)

### RelatÃ³rio de Cobertura HTML

Ao executar os testes com a flag `--coverage`, um relatÃ³rio HTML detalhado Ã© gerado automaticamente na pasta `backend/var/coverage`. Para visualizar:

1. Abra o arquivo `backend/var/coverage/index.html` no seu navegador
2. Navegue pelas classes e mÃ©todos para ver detalhes da cobertura linha por linha

AlÃ©m do HTML, tambÃ©m Ã© gerado um arquivo texto com resumo em `backend/var/coverage.txt`.

## Estrutura dos Testes

Os testes estÃ£o organizados em duas categorias:

- **Testes UnitÃ¡rios** (`tests/Unit`): Validam a lÃ³gica de negÃ³cio das entidades e casos de uso do domÃ­nio
- **Testes de IntegraÃ§Ã£o** (`tests/Feature`): Testam a interaÃ§Ã£o entre as camadas da aplicaÃ§Ã£o, incluindo repositÃ³rios e controllers

## ConfiguraÃ§Ã£o

A configuraÃ§Ã£o dos testes estÃ¡ definida no arquivo `backend/phpunit.xml`, que especifica:
- ConexÃ£o com PostgreSQL para testes de integraÃ§Ã£o
- ConfiguraÃ§Ãµes de ambiente de teste
- DiretÃ³rios de cobertura de cÃ³digo

# API Documentation

O [postman](https://www.postman.com) foi usado para criar a documentaÃ§Ã£o da API. O workspace com a collection estÃ¡ [disponÃ­vel aqui](https://app.getpostman.com/join-team?invite_code=a8f7c5db50618a4d057b1e50ca129cef16d68fbd74f03c9d4f532c18e9fff4c3&target_code=0249e09988430bb18a9413c8067664c2). VocÃª notarÃ¡ que cada recurso estÃ¡ organizado em pastas:

- pasta `usuario`: CRUD de usuÃ¡rios do sistema (mecÃ¢nicos, atendentes, etc...)
- pasta `servico`: CRUD de serviÃ§os da oficina, como troca de Ã³leo, revisÃµes e etc...
- pasta `material: peÃ§a / insumo`: CRUD de materiais (peÃ§as e insumos) usados nas ordens de serviÃ§o, como pastilha de freio, filtros de ar e Ã³leo, etc...
- pasta `cliente`: CRUD de clientes da oficina
- pasta `veiculo`: CRUD de veÃ­culos dos clientes
- pasta `ordem`: CRUD da ordem de serviÃ§o
- pasta `auth`: AutenticaÃ§Ã£o de usuÃ¡rios do sistema.

No momento da inicializaÃ§Ã£o dos containers mapeados no [docker-compose.yaml](./docker-compose.yml), a base de dados Ã© populada com um usuÃ¡rio de teste, como descrito no arquivo [DatabaseSeeder.php](./backend/database/seeders/DatabaseSeeder.php). VocÃª pode usar os dados desse usuÃ¡rio para obter um token JWT e testar todo os fluxos da API. Os dados desse usuÃ¡rio sÃ£o os seguintes:

- UsuÃ¡rio: `soat@example.com`
- Senha: `padrao`

A pasta `auth` contÃ©m um Ãºnico endpoint nomeado "login". Ã‰ esse endpoint que vocÃª vai usar para obter um token JWT. O postman nos oferece algumas features muito legais, uma delas Ã© a execuÃ§Ã£o de scripts prÃ© e pÃ³s request. O endpoint "login" dentro da pasta `auth` tem um script pÃ³s requisiÃ§Ã£o, que basicamente pega o token jwt devolvido, e salva na variÃ¡vel de ambiente "token".

![postman-postscripts.png](./docs/img/postman-postscripts.png)

Sendo assim, vocÃª nÃ£o precisa copiar o token devolvido, ir nas variÃ¡veis de ambiente e colar como valor. Isso Ã© feito automaticamente na devoluÃ§Ã£o dele na responde do endpoint.

Falando em variÃ¡veis de ambiente, todas as variÃ¡veis de ambiente estÃ£o em contexto de collection. Isso significa que a collection quando exportada ou importada (que nÃ£o Ã© o caso aqui) jÃ¡ vai com as variÃ¡veis junto.

![variaveis-postman.png](./docs/img/variaveis-postman.png)

A maior parte dos endpoints da API, estÃ£o protegidos por um middleware que exige que um token JWT vÃ¡lido seja informado, exceto o endpoint `/ping` que Ã© para teste rÃ¡pido, e os endpoints de aprovaÃ§Ã£o ou reprovaÃ§Ã£o de uma ordem de serviÃ§o informada como parÃ¢metro de URL, conforme exemplificado nos endpoints:

![variaveis-postman.png](./docs/img/endpoints-aprovacao-desaprovacao.png)

Um Ãºltimo ponto sobre a documentaÃ§Ã£o da API, Ã© que ela tem exemplos de resposta de sucesso e erro para cada endpoint:

![variaveis-postman.png](./docs/img/ver-exemplo-de-respostas.png)

Clique nas setinhas em cada endpoint para ver os exemplos de respostas:

![variaveis-postman.png](./docs/img/exemplo-respostas-aberto.png)

# Fluxo principal da API
Sem dÃºvidas, o fluxo principal da API Ã© o cadastro e gestÃ£o de ordens de serviÃ§o. Nosso fluxo de cadastro de ordens funciona da seguinte forma:

- Cadastro da ordem: informando somente uuid do cliente e veÃ­culo
- Cadastro de materiais (peÃ§as e insumos) na OS: use o endpoint dentro de `ordem/ordem-material/adiciona material`
- Cadastro de serviÃ§os na OS: use o endpoint dentro de `ordem/ordem-servico/adiciona servico`

Feito isso, a ordem estarÃ¡ montada com os materiais necessÃ¡rios e serviÃ§os que serÃ£o executados. Feito isso, as prÃ³ximas aÃ§Ãµes a serem tomadas, sÃ£o de atualizaÃ§Ã£o de status. Para isso use o endpoint `ordem/update status`.

# Clean architecture

O projeto foi organizado usando clean architecture. Essa organizaÃ§Ã£o pode ser vista dentro da pasta `backend/app` e vamos entrar em detalhesa agora.

- Entidades e casos de uso: `backend/app/Domain`
- Controllers (da clean arch): `backend/app/Infrastructure/Controller`
- Gateway: `backend/app/Infrastructure/Gateway`
- Presenters: `backend/app/Infrastructure/Presenters`
- Camadas mais externas:
    - Banco de dados: `backend/app/Infrastructure/Repositories`
    - Web: `backend/app/Http/`

Algumas boas prÃ¡ticas e padrÃµes foram adotados para desenvoler o projeto, como por exemplo clean code, SOLID, Repository pattern e Object Calistenics.

Nossos mÃ©todos possuem nomes simples e claros, que demonstram o que fazem, como por exemplo:
```php
public function validarNome(): void
{
    if (strlen(trim($this->nome)) < 3) {
        throw new InvalidArgumentException('Nome deve ter pelo menos 3 caracteres');
    }
}
```

Codificamos para interfaces e nÃ£o para implementaÃ§Ãµes concretas, como Ã© o caso da interface que gera o JWT:
```php
interface TokenServiceInterface
{
    public function generate(array $claims): string;
    public function validate(string $token): ?JsonWebTokenFragment;
    public function refresh(string $token): string;
    public function invalidate(string $token): void;
}
```

Nossas dependÃªncias sÃ£o de fora para dentro:

![clean-arch.png](./docs/img/clean-arch.png)

Nossas regras de negÃ³cio estÃ£o seguras nos _use cases_ e _entities_, conforme deve ser.
